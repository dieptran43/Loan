{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train['source'] = 'Train'\n",
    "test['source'] = 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Both DataFrames for faster Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muralish\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([train,test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Numerical Null Values using MICE in Azure ML Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({ x: data[x] for x in data.columns})\n",
    "submission.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Categorial Null Values using Pivot Table and Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "Dependents = data.pivot_table(values='Dependents',\n",
    "                                   columns='Education',\n",
    "                                   aggfunc=lambda x: x.mode().iat[0])\n",
    "Dep_bool = data['Dependents'].isnull() \n",
    "data.loc[Dep_bool,'Dependents'] = data.loc[Dep_bool,'Education'].apply(lambda x: Dependents[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "gender = data.pivot_table(values='Gender',\n",
    "                                   columns='Education',\n",
    "                                   aggfunc=lambda x: x.mode().iat[0])\n",
    "gender_bool = data['Gender'].isnull() \n",
    "data.loc[gender_bool,'Gender'] = data.loc[gender_bool,'Education'].apply(lambda x: gender[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "married = data.pivot_table(values='Married',\n",
    "                                   columns='Education',\n",
    "                                   aggfunc=lambda x: x.mode().iat[0])\n",
    "married_bool = data['Married'].isnull() \n",
    "data.loc[married_bool,'Married'] = data.loc[married_bool,'Education'].apply(lambda x: married[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "self_employed = data.pivot_table(values='Self_Employed',\n",
    "                                   columns='Education',\n",
    "                                   aggfunc=lambda x: x.mode().iat[0])\n",
    "self_bool = data['Self_Employed'].isnull() \n",
    "data.loc[self_bool,'Self_Employed'] = data.loc[self_bool,'Education'].apply(lambda x: self_employed[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplicantIncome      752\n",
       "CoapplicantIncome    437\n",
       "Credit_History        81\n",
       "Dependents             4\n",
       "Education              2\n",
       "Gender                 2\n",
       "LoanAmount           259\n",
       "Loan_Amount_Term      32\n",
       "Loan_ID              981\n",
       "Loan_Status            3\n",
       "Married                2\n",
       "Property_Area          3\n",
       "Self_Employed          2\n",
       "source                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(('Loan_ID'),axis=1) #Remove unwanted columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education\n",
      "Gender\n",
      "Married\n",
      "Property_Area\n",
      "Self_Employed\n"
     ]
    }
   ],
   "source": [
    "to_label = ['Education','Gender','Married','Property_Area','Self_Employed']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for x in to_label:\n",
    "    print(x)\n",
    "    data[x] = le.fit_transform(data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Credit_History'] > 0.5 , 'Credit_History'] = 1\n",
    "data.loc[data['Credit_History'] < 0.5 , 'Credit_History'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Credit_History'] = data['Credit_History'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Dependents'] ==  '3+' , 'Dependents'] = 3\n",
    "data['Dependents'] = data['Dependents'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_variables = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "data[normalize_variables] = sc_x.fit_transform(data[normalize_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_onehot = ['Dependents','Property_Area']\n",
    "data = pd.get_dummies(data, columns=encode_onehot)\n",
    "for count in encode_onehot:\n",
    "     data=data.drop(count + '_0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['source'] =='Train']\n",
    "x_test = data[data['source'] =='Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Loan_Status'] \n",
    "x_train = train.drop('Loan_Status',axis=1)\n",
    "x_train = train.drop('source',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.drop('Loan_Status',axis=1)\n",
    "x_test = x_test.drop('source',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.drop('Loan_Status',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_y = LabelEncoder()\n",
    "y_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc= RandomForestClassifier(max_depth=3,min_samples_split=3,n_estimators=100)\n",
    "rfc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for x in y_pred:\n",
    "    if x>0:\n",
    "        arr.append('Y')\n",
    "    else:\n",
    "        arr.append('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(arr)\n",
    "submission.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra scratch work for better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the training data into two to c/heck accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "lr = LinearRegression()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc= RandomForestClassifier(max_depth=3,min_samples_split=3,n_estimators=100,max_features=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel = 'linear',)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "train_x_1 , test_x_1, train_y_1, test_y_1 = train_test_split(x_train,y_train,test_size=0.33)\n",
    "\n",
    "def cm(model,train_x,train_y,test_x,test_y):\n",
    "    model.fit(train_x, train_y)\n",
    "    y_pred = model.predict(test_x)\n",
    "    cm = confusion_matrix(test_y,y_pred)\n",
    "    return cm\n",
    "\n",
    "model_acc = cm(rfc,train_x_1,train_y_1,test_x_1,test_y_1)\n",
    "accuracy = (model_acc[0][0]+model_acc[1][1])/(model_acc[0][0]+model_acc[0][1]+model_acc[1][0]+model_acc[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7881773399014779"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearch to identify the best parameters for RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for precision_score\n",
      "{'max_depth': 25, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for precision_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg        32        38\n",
      "pos         6       127\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>mean_test_accuracy_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.820</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.818</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.818</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.820</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.815</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_precision_score  mean_test_recall_score  \\\n",
       "0                      0.806                   0.983   \n",
       "1                      0.806                   0.979   \n",
       "2                      0.804                   0.983   \n",
       "3                      0.806                   0.983   \n",
       "4                      0.803                   0.979   \n",
       "\n",
       "   mean_test_accuracy_score param_max_depth param_min_samples_split  \\\n",
       "0                     0.820               3                       3   \n",
       "1                     0.818               3                       3   \n",
       "2                     0.818               3                       5   \n",
       "3                     0.820               3                       5   \n",
       "4                     0.815               3                      10   \n",
       "\n",
       "  param_n_estimators  \n",
       "0                100  \n",
       "1                300  \n",
       "2                100  \n",
       "3                300  \n",
       "4                100  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [3, 5, 10], \n",
    "    'n_estimators' : [100, 300],\n",
    "    'max_depth': [3, 5, 15, 25],\n",
    "    \n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "def grid_search_wrapper(refit_score='precision_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n",
    "                           cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(train_x_1, train_y_1)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(test_x_1)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(test_y_1, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search\n",
    "grid_search_clf = grid_search_wrapper(refit_score='precision_score')\n",
    "results = pd.DataFrame(grid_search_clf.cv_results_)\n",
    "#results = results.sort_values(by='mean_test_precision_score', ascending=False)\n",
    "results[['mean_test_precision_score', 'mean_test_recall_score', 'mean_test_accuracy_score', 'param_max_depth', 'param_min_samples_split', 'param_n_estimators']].round(3).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
